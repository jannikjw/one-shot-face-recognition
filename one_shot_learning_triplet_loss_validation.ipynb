{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TwXdV7BHeoT"
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "qaGV91DX1SIf",
    "outputId": "41e58374-8636-4077-c5b5-15867d881dfa"
   },
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, training, fixed_image_standardization\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from natsort import natsorted\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile \n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import src\n",
    "from tqdm.notebook import tqdm\n",
    "from src.utils.celeba_helper_v2 import CelebADataset, CelebAClassifier, CelebADatasetTriplet #save_file_names\n",
    "from src.utils.loss_functions import TripletLoss\n",
    "import shutil\n",
    "# from torchsummary import summary\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IjCxN6Q4xkoN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nGPU = torch.cuda.device_count()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the necessary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "    \n",
    "if not os.path.exists(\"loss_curves\"):\n",
    "    os.makedirs(\"loss_curves\")\n",
    "    \n",
    "if not os.path.exists(\"pytorch_objects\"):\n",
    "    os.makedirs(\"pytorch_objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the label file after MTCNN face extraction (enable if you don't have the updated file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_mapping_file = 'data/identity_CelebA_train_test_split.txt'\n",
    "# img_folder = 'data/img_align_celeba_mtcnn'\n",
    "\n",
    "# label_df = pd.read_csv(orig_mapping_file, header=None, sep=\" \", names=[\"file_name\", \"person_id\", \"is_train\"])\n",
    "\n",
    "# count=0\n",
    "# files = []\n",
    "# for filename in os.listdir(img_folder):\n",
    "#     files.append(filename)\n",
    "\n",
    "# file_names = label_df[label_df[\"file_name\"].isin(files)]\n",
    "# file_names.to_csv(\"data/identity_CelebA_train_test_split_mtcnn.txt\", sep=\" \", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7Ta2e8wa3UM"
   },
   "source": [
    "# Define CelebA Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADatasetTriplet(CelebADataset):\n",
    "    def __init__(self, root_dir, mapping_file: str, transform=None, \n",
    "                train: bool = True, img_ext: str = 'jpg'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          root_dir (string): Directory with all the images\n",
    "          mapping_file (string): File path to mapping file from image to person\n",
    "          transform (callable, optional): transform to be applied to each image sample\n",
    "        \"\"\"\n",
    "        # Read names of images in the root directory\n",
    "        image_names = os.listdir(root_dir)\n",
    "        image_names = [x for x in image_names if x.split(\".\")[-1]==img_ext]\n",
    "        print(f'Image names size is: {len(image_names)}')\n",
    "        self.return_triplets = True\n",
    "        self.mode = 'train'\n",
    "\n",
    "        self.file_label_mapping = pd.read_csv(\n",
    "            mapping_file, header=None, sep=\" \", names=[\"file_name\", \"person_id\", \"is_train\"]\n",
    "        )\n",
    "        self.file_label_mapping = self.file_label_mapping.sort_values(by=[\"file_name\"]).reset_index(drop=True)\n",
    "\n",
    "        all_images_idx = self.file_label_mapping.index.values\n",
    "\n",
    "        self.train_df = self.file_label_mapping[self.file_label_mapping[\"is_train\"]==1]\n",
    "        train_images_idx = self.train_df.index.values\n",
    "        \n",
    "        # Define the images that are available for triplet selectiontriplet_idx dataframe\n",
    "        # fix test dataframe - pull out from test_df set of n=3 images per person as real_test_set for accuracy test.\n",
    "        # these images in real_test will not be used during finetuning but the labels have been seen (NOT UNSEEN PPL)\n",
    "        non_train_df = self.file_label_mapping[self.file_label_mapping[\"is_train\"]==0]\n",
    "        test_df = pd.DataFrame.copy(non_train_df)\n",
    "        test_df['count'] = test_df.groupby(\"person_id\")['person_id'].transform('size')\n",
    "        test_df = test_df[test_df['count'] >=3]\n",
    "        test_df = test_df.groupby('person_id', sort=False).sample(n=3, random_state=42).sort_values(by='file_name')\n",
    "        self.test_df = test_df.iloc[:,:-1] # drop count column\n",
    "\n",
    "        # test set\n",
    "        test_images_idx = self.test_df.index.values\n",
    "\n",
    "        # rest images that are available for triplets\n",
    "        triplet_images_idx = set(all_images_idx)- set(train_images_idx) - set(test_images_idx)\n",
    "        \n",
    "        self.train_triplet_df = self.file_label_mapping[self.file_label_mapping.index.isin(triplet_images_idx)] # images that are available for triplet creation during training\n",
    "        self.test_triplet_df = self.file_label_mapping[self.file_label_mapping.index.isin(test_images_idx)]  # images that are available for triplet creation during validation\n",
    "           \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = natsorted(image_names)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_label_mapping)\n",
    "\n",
    "    def get_image_label(self, idx):\n",
    "        filename = self.file_label_mapping.loc[idx, 'file_name']\n",
    "\n",
    "        img_path = os.path.join(self.root_dir, filename)\n",
    "        # Load image and convert it to RGB\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            raise(f\"get_train is {get_train}, idx is {idx}, image name is: {filename}\")\n",
    "        # Apply transformations to the image\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.file_label_mapping[\"person_id\"][self.file_label_mapping[\"file_name\"]==filename].iloc[0]\n",
    "\n",
    "        return img, label, filename\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.return_triplets:\n",
    "            anchor, anchor_label, anchor_name = self.get_image_label(idx)\n",
    "\n",
    "            if self.mode == 'train':\n",
    "                triplet_df = self.train_triplet_df\n",
    "            elif self.mode == 'validation' or self.mode == 'test':\n",
    "                triplet_df = self.test_triplet_df\n",
    "            else:\n",
    "                raise Exception('Specify dataset mode.')\n",
    "                \n",
    "            # loading image lists\n",
    "            pos_list = triplet_df[\"file_name\"][(triplet_df[\"person_id\"]==anchor_label)]\n",
    "            neg_list = triplet_df[\"file_name\"][(triplet_df[\"person_id\"]!=anchor_label)]\n",
    "\n",
    "            \n",
    "            # Picking positive\n",
    "            if len(pos_list) == 0:\n",
    "                positive = anchor\n",
    "            else:\n",
    "                pos_name = pos_list.sample(n=1) #random_state=42\n",
    "                pos_idx = pos_name.index[0]\n",
    "\n",
    "                positive, pos_label, pos_name = self.get_image_label(pos_idx)\n",
    "\n",
    "            # Picking negative image\n",
    "            neg_name = neg_list.sample(n=1, random_state=42)\n",
    "            neg_idx = neg_name.index[0]\n",
    "\n",
    "            negative, neg_label, neg_name = self.get_image_label(neg_idx)\n",
    "\n",
    "            return anchor, positive, negative, anchor_label\n",
    "        else:\n",
    "            anchor, anchor_label, anchor_name = self.get_image_label(idx)\n",
    "            return anchor, anchor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hkdQB_ZODfmw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image names size is: 202599\n"
     ]
    }
   ],
   "source": [
    "## Load the dataset\n",
    "# Path to directory with all the images\n",
    "img_folder = 'data/img_align_celeba_mtcnn'\n",
    "mapping_file = 'data/identity_CelebA_train_test_split.txt'\n",
    "type_of_experiment = \"celebA_mtcnn\" # if using baseline then use baseline also in name\n",
    "\n",
    "# Spatial size of training images, images are resized to this size.\n",
    "image_size = 160\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "# Load the dataset from file and apply transformations\n",
    "celeba_dataset = CelebADatasetTriplet(img_folder, mapping_file, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 10177\n",
      "Size of test set: 28692\n",
      "Number of images available for triplet selection: 163730\n",
      "Size of validation set: 2869\n"
     ]
    }
   ],
   "source": [
    "# Define train, validation and test images\n",
    "flm = celeba_dataset.file_label_mapping\n",
    "\n",
    "# Subset data\n",
    "# num_people_subset = 1000\n",
    "# people_subset = np.random.choice(flm['person_id'], num_people_subset)\n",
    "# flm = flm[flm['person_id'].isin(people_subset)]\n",
    "\n",
    "all_images_idx = flm.index.values\n",
    "train_images_idx = flm[flm[\"is_train\"]==1][\"file_name\"].index.values\n",
    "print(f'Size of train set: {len(train_images_idx)}')\n",
    "\n",
    "# test set\n",
    "test_images_idx = celeba_dataset.test_df.index.values\n",
    "print(f'Size of test set: {len(test_images_idx)}')\n",
    "\n",
    "# rest images that are available for triplets\n",
    "triplet_images_idx = set(all_images_idx)- set(train_images_idx) - set(test_images_idx)\n",
    "print(f'Number of images available for triplet selection: {len(triplet_images_idx)}')\n",
    "\n",
    "# create validation set of anchors from test set\n",
    "np.random.shuffle(test_images_idx)\n",
    "val_images_idx = test_images_idx[:int(0.1 * len(test_images_idx))]\n",
    "print(f'Size of validation set: {len(val_images_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dP2V5_HTDaMt"
   },
   "outputs": [],
   "source": [
    "## Create a dataloader\n",
    "# Batch size during training\n",
    "batch_size = 512\n",
    "# Number of workers for the dataloader\n",
    "num_workers = 8 * nGPU if device.type == 'cuda' else 2\n",
    "# Whether to put fetched data tensors to pinned memory\n",
    "pin_memory = True if device.type == 'cuda' else False\n",
    "\n",
    "# celeba_dataloader = torch.utils.data.DataLoader(celeba_dataset,  # type: ignore\n",
    "#                                                 batch_size=batch_size,\n",
    "#                                                 num_workers=num_workers,\n",
    "#                                                 prefetch_factor=1000,\n",
    "#                                                 pin_memory=pin_memory,\n",
    "#                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(celeba_dataset,  # type: ignore\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=1000,\n",
    "                                            pin_memory=pin_memory,\n",
    "                                            sampler=SubsetRandomSampler(train_images_idx))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(celeba_dataset,  # type: ignore\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=1000,\n",
    "                                            pin_memory=pin_memory,\n",
    "                                            sampler=SubsetRandomSampler(val_images_idx))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(celeba_dataset,  # type: ignore\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                            prefetch_factor=1000,\n",
    "                                            pin_memory=pin_memory,\n",
    "                                            sampler=SubsetRandomSampler(test_images_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceNet Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the resnet model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "margin = 0.5\n",
    "gamma = 0.1\n",
    "lr = 0.1\n",
    "epochs = 200\n",
    "\n",
    "schedule = [40, 80, 130, 160]\n",
    "str_schedule = \"_\".join(map(str, schedule)) #'30_50_70_80'\n",
    "\n",
    "resnet = InceptionResnetV1(pretrained='vggface2')\n",
    "if nGPU > 1:\n",
    "    print(\"Let's use\", nGPU, \"GPUs!\")\n",
    "    resnet = torch.nn.DataParallel(resnet)\n",
    "    \n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing all the layers except last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = resnet.state_dict()\n",
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == False:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"last\" not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "set_parameter_requires_grad(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.last_linear.weight\n",
      "module.last_bn.weight\n",
      "module.last_bn.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=lr)\n",
    "criterion = TripletLoss(margin=margin)\n",
    "\n",
    "# multistep LR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=schedule, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 160, 160])\n",
      "torch.Size([1, 3, 160, 160])\n",
      "The distance between anchor and positive: 0.7654615640640259\n",
      "The distance between anchor and negative: 1.47859525680542\n"
     ]
    }
   ],
   "source": [
    "resnet.eval().to(device)\n",
    "\n",
    "test_anchor, test_pos, test_neg, anchor_label = celeba_dataset[1]\n",
    "# test_anchor, test_pos, test_neg, anchor_label = test_anchor[1], test_pos[1], test_neg[1], anchor_label[1]\n",
    "print(test_anchor.shape)\n",
    "\n",
    "test_anchor_emb = resnet(test_anchor[None, :].to(device))\n",
    "test_pos_emb = resnet(test_pos[None, :].to(device))\n",
    "test_neg_emb = resnet(test_neg[None, :].to(device))\n",
    "print(test_anchor[None, :].shape)\n",
    "\n",
    "pos_dist = criterion.cal_distance(test_anchor_emb, test_pos_emb)\n",
    "neg_dist = criterion.cal_distance(test_anchor_emb, test_neg_emb)\n",
    "\n",
    "print(\"The distance between anchor and positive: {}\".format(pos_dist[0]))\n",
    "print(\"The distance between anchor and negative: {}\".format(neg_dist[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3812cb586140adaf97bf31896747c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cabbd546dd4615a7d1b54e550e03c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_total = []\n",
    "val_loss_total = []\n",
    "learning_rates = []\n",
    "celeba_dataset.return_triplets = True\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\", leave=True, position=0):\n",
    "    running_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    resnet.train()\n",
    "    celeba_dataset.mode='train'\n",
    "    for step, (anchors, positives, negatives, labels) in enumerate(tqdm(train_loader, \n",
    "                                                desc=\"Training\", position=1, leave=False)):\n",
    "        anchors = anchors.to(device)\n",
    "        positives = positives.to(device)\n",
    "        negatives = negatives.to(device)\n",
    "        if anchors.shape[0] == 1:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        anchor_emb = resnet(anchors)\n",
    "        positive_emb = resnet(positives)\n",
    "        negative_emb = resnet(negatives)\n",
    "\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    resnet.eval()\n",
    "    celeba_dataset.mode='validation'\n",
    "    for step, (anchors, positives, negatives, labels) in enumerate(tqdm(val_loader, \n",
    "                                                desc=\"Validation\", position=1, leave=False)):\n",
    "        anchors = anchors.to(device)\n",
    "        positives = positives.to(device)\n",
    "        negatives = negatives.to(device)\n",
    "        if anchors.shape[0] == 1:\n",
    "            continue\n",
    "\n",
    "        anchor_emb = resnet(anchors)\n",
    "        positive_emb = resnet(positives)\n",
    "        negative_emb = resnet(negatives)\n",
    "\n",
    "        loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "        val_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    loss_total.append(np.mean(running_loss))\n",
    "    val_loss_total.append(np.mean(val_loss))\n",
    "    learning_rates.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "    print(\"Epoch: {}/{} - Loss: {:.4f}. Validation Loss: {:.4f}\".format(epoch, epochs, np.mean(running_loss), np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the loss and learning rates to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the loss and learning rates to a file\n",
    "loss_to_file = np.array(loss_total)\n",
    "val_loss_to_file = np.array(val_loss_total)\n",
    "lr_to_file = np.array(learning_rates)\n",
    "\n",
    "with open(f\"loss_curves/loss_file_{type_of_experiment}_epoch{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.npy\", \"wb\") as loss_file:\n",
    "    np.save(loss_file, loss_to_file)\n",
    "    np.save(loss_file, lr_to_file)\n",
    "\n",
    "with open(f\"loss_curves/loss_file_val_{type_of_experiment}_epoch{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.npy\", \"wb\") as loss_file:\n",
    "    np.save(loss_file, val_loss_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing loss function\n",
    "plt.plot(loss_total, label='Train loss')\n",
    "plt.plot(val_loss_total, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"TripletLoss\")\n",
    "plt.title(\"Training Triplet Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"loss_curves/loss_curve_{type_of_experiment}_epoch{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Learning rates with epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing loss function\n",
    "plt.plot(learning_rates)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Learning Rate\")\n",
    "plt.savefig(f\"loss_curves/learning_curve_{type_of_experiment}_epoch{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"models/facenet_model_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.pth\"\n",
    "if not os.path.exists(model_path):\n",
    "    torch.save(resnet, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_path = f\"models/facenet_model_statedict_{type_of_experiment}_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.pth\"\n",
    "if not os.path.exists(model_state_path):\n",
    "    torch.save(resnet.state_dict(), model_state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval().to(device)\n",
    "\n",
    "test_anchor, test_pos, test_neg, anchor_label = celeba_dataset[1]\n",
    "# test_anchor, test_pos, test_neg, anchor_label = test_anchor[1], test_pos[1], test_neg[1], anchor_label[1]\n",
    "\n",
    "test_anchor_emb = resnet(test_anchor[None, :].to(device))\n",
    "test_pos_emb = resnet(test_pos[None, :].to(device))\n",
    "test_neg_emb = resnet(test_neg[None, :].to(device))\n",
    "\n",
    "pos_dist = criterion.cal_distance(test_anchor_emb, test_pos_emb)\n",
    "neg_dist = criterion.cal_distance(test_anchor_emb, test_neg_emb)\n",
    "\n",
    "print(\"The distance between anchor and positive: {}\".format(pos_dist[0]))\n",
    "print(\"The distance between anchor and negative: {}\".format(neg_dist[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Vault folder and vault mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault_path = \"data/oneshot_vault_mtcnn_baseline\"\n",
    "label_file = \"data/identity_vault_person_mtcnn_baseline.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the vault and test label file\n",
    "if not os.path.exists(vault_path):\n",
    "    os.makedirs(vault_path)\n",
    "\n",
    "    # copying train images in the vault location and appending the label file\n",
    "    with open(label_file, \"w\") as v_file:\n",
    "        for i in range(len(celeba_dataset.train_df)):\n",
    "            file = celeba_dataset.train_df.iloc[i][\"file_name\"]\n",
    "            label = str(celeba_dataset.train_df.iloc[i][\"person_id\"])\n",
    "            v_file.write(file+\" \"+label+\"\\n\")\n",
    "\n",
    "            # copying the file to the new folder\n",
    "            src_file = os.path.join(img_folder, file)\n",
    "            dst_file = os.path.join(vault_path, file)\n",
    "            shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vault embeddings or load vault embeddings if already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create embeddings    \n",
    "def create_embeddings(celeba_dataloader, model):\n",
    "    # initializing embedding vector and gt_label list\n",
    "    embeddings = torch.tensor([])\n",
    "    gt_labels = []\n",
    "    \n",
    "    # creating embeddings \n",
    "    for step, (anchors, positives, negatives, labels) in enumerate(tqdm(celeba_dataloader, \n",
    "                                                            desc=\"Training\", position=1)):\n",
    "        anchors = anchors.to(device)\n",
    "        img_embs = model(anchors).detach().cpu()\n",
    "        \n",
    "        embeddings = torch.cat([embeddings, img_embs])\n",
    "        gt_labels.extend(labels)\n",
    "\n",
    "    return embeddings, gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vault_embeddings_file = f\"pytorch_objects/vault_embeddings_type_{type_of_experiment}_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.pickle\"\n",
    "vault_gt_labels_file = f\"pytorch_objects/vault_gt_labels_type_{type_of_experiment}_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.pickle\"\n",
    "\n",
    "# setting model to eval mode\n",
    "resnet.eval().to(device)\n",
    "\n",
    "celeba_dataset.mode='train'\n",
    "if not os.path.exists(vault_embeddings_file) or not os.path.exists(vault_gt_labels_file):\n",
    "    print('Creating embeddings...')\n",
    "    embeddings, gt_labels = create_embeddings(celeba_dataloader = train_loader,\n",
    "                                              model = resnet)\n",
    "    \n",
    "    torch.save(embeddings, vault_embeddings_file)\n",
    "    torch.save(gt_labels, vault_gt_labels_file)\n",
    "    print('Created embeddings.')\n",
    "else:\n",
    "    embeddings = torch.load(vault_embeddings_file)\n",
    "    gt_labels = torch.load(vault_gt_labels_file)\n",
    "    print('Embeddings loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "embeddings = embeddings.detach().cpu()\n",
    "gt_labels = torch.tensor(gt_labels)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(embeddings, gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image:\n",
    "\n",
    "def calculate_label(test_images, embeddings, gt_labels, embedding_model):\n",
    "    # test_image_file = \"s1_9.pgm\"\n",
    "    test_images = test_images.to(device)\n",
    "\n",
    "    test_img_emb = embedding_model(test_images).detach().cpu()\n",
    "    test_img_emb = test_img_emb[None,:].transpose(2,1).to(device)\n",
    "\n",
    "    distance_mat = (test_img_emb - embeddings).pow(2).sum(axis=1).transpose(1,0)\n",
    "    test_label_pred = gt_labels[torch.argmin(distance_mat, axis=1)]\n",
    "\n",
    "    return test_label_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = torch.tensor(gt_labels)\n",
    "torch.is_tensor(gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_dataset.return_triplets = False\n",
    "\n",
    "test_predictions = torch.tensor([]).type(torch.int)\n",
    "test_gt_labels = torch.tensor([]).type(torch.int)\n",
    "\n",
    "test_embeddings = torch.tensor([])\n",
    "\n",
    "gt_labels = gt_labels.detach().cpu()\n",
    "\n",
    "for i, (test_imgs, test_labels) in enumerate(tqdm(test_loader, desc=\"Creating embeddings\", position=1, leave=False)):\n",
    "    test_gt_labels = torch.cat([test_gt_labels, test_labels])\n",
    "    test_imgs = test_imgs.to(device)\n",
    "    test_embs = resnet(test_imgs).detach().cpu()\n",
    "    test_embeddings = torch.cat([test_embeddings, test_embs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_file = f\"pytorch_objects/test_embeddings_type_{type_of_experiment}_epochs_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.pickle\"\n",
    "test_gt_labels_file = f\"pytorch_objects/test_gt_labels_type_{type_of_experiment}_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.pickle\"\n",
    "\n",
    "if not os.path.exists(test_embeddings_file) or not os.path.exists(test_gt_labels_file):\n",
    "    torch.save(test_embeddings, test_embeddings_file)\n",
    "    torch.save(test_gt_labels, test_gt_labels_file)\n",
    "# test_embeddings = torch.load(test_embeddings_file)\n",
    "# test_gt_labels = torch.load(test_gt_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = knn.score(test_embeddings, test_gt_labels)\n",
    "\n",
    "print(f'trained model: Accuracy = {score}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"loss_curves/test_accuracy_type_{type_of_experiment}_epochs{epochs}_margin{margin}_lr{lr}_schedule{str_schedule}.txt\", 'w') as test_acc_file:\n",
    "    test_acc_file.write(f'trained model: Accuracy = {score}.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9TwXdV7BHeoT",
    "k0mnB3l9Ha9D",
    "w7Ta2e8wa3UM",
    "gU46F-JyF2PA",
    "3JLywKFbopy9",
    "aEBA_FaWHpgY",
    "IJAT0dvwHfaa",
    "vqPiqddKE51v"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "faceenv2",
   "language": "python",
   "name": "faceenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "915d08fc081d212946bc55eb28a5b744f9509c1c054f3f4f212ad3c247333ef8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
