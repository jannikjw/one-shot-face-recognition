{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Run Notebook on Colab GCP VM Instance as CUDA is needed**"
      ],
      "metadata": {
        "id": "m7BAx1Yi80pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "id": "L8G5Orw9cWA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUOLCo77OUZi",
        "outputId": "980b1ab2-4825-4228-8c79-0b68904b9241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 22 15:52:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    14W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile \n",
        "import gdown\n",
        "import torch\n",
        "from torch import positive, tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "jYKAfgcTvOAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip File Creation Function\n",
        "def back_up(folder):\n",
        "  t = folder +'.zip'\n",
        "  !zip -r $t $folder -qq\n",
        "  files.download(t)\n",
        "  print('zip file created')"
      ],
      "metadata": {
        "id": "IyYsfxADv0gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Image Files for CelebA"
      ],
      "metadata": {
        "id": "Rx0tp5moyTl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fetch data from Google Drive\n",
        "data_root = 'data'\n",
        "\n",
        "# Path to download the dataset to - One Shot CelebA\n",
        "img_download_path = f'data/train_celeba_one_shot.zip'\n",
        "mapping_download_path = f'data/identity_CelebA.txt'\n",
        "\n",
        "# Create required directories\n",
        "if not os.path.exists(data_root):\n",
        "  os.makedirs(data_root)"
      ],
      "metadata": {
        "id": "dYQb3QgPvln5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manually upload celeba zip file and mapping file to google colab**"
      ],
      "metadata": {
        "id": "-Kftne_Si2qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded file \n",
        "with zipfile.ZipFile(img_download_path, 'r') as ziphandler:\n",
        "  ziphandler.extractall(data_root)\n",
        "\n",
        "  print('Dataset fully extracted.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iowsu_VHv0yN",
        "outputId": "a95924b5-8e0e-4d2d-c7ea-4d8bdf2dadee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset fully extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to directory with all the images (train one shot, test, labels)\n",
        "train_img_folder = 'data/train_celeba_one_shot'\n",
        "mapping_file = 'data/identity_CelebA.txt'"
      ],
      "metadata": {
        "id": "2T1I-iHfbAQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image File Names\n",
        "img_file_names = os.listdir(train_img_folder)\n",
        "img_file_names = natsorted(img_file_names)\n",
        "img_file_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BASGyLgbFpE",
        "outputId": "1e8f859c-58ca-49b5-8dd5-8484aa77470b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000001.jpg', '000002.jpg', '000003.jpg', '000004.jpg', '000005.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image File Paths\n",
        "img_file_paths = [os.path.join(train_img_folder, fname) for fname in img_file_names]\n",
        "img_file_paths[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxqeacyIbOCu",
        "outputId": "6bcc9931-8801-4888-87b6-02fcdb175fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/train_celeba_one_shot/000001.jpg',\n",
              " 'data/train_celeba_one_shot/000002.jpg',\n",
              " 'data/train_celeba_one_shot/000003.jpg',\n",
              " 'data/train_celeba_one_shot/000004.jpg',\n",
              " 'data/train_celeba_one_shot/000005.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File Nums to use later to save Augmented Images\n",
        "f_num = [f.split('.jpg')[0] for f in img_file_names]\n",
        "f_num[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YO1lNbhiKVe",
        "outputId": "1685093e-ddb4-40e0-9065-74937c90951b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000001', '000002', '000003', '000004', '000005']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image File Label mapping\n",
        "df = pd.read_csv(\n",
        "            mapping_file, header=None, sep=\" \", names=[\"file_name\", \"person_id\"]\n",
        "        )\n",
        "df = df[df['file_name'].isin(img_file_names)] # only keep files in mapping file that are in the train_img_folder\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0qe4iFsKbSfI",
        "outputId": "c5bf7f22-21ec-4e12-823b-8303088f5984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22528728-331b-48e8-a329-ab898d2c2951\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22528728-331b-48e8-a329-ab898d2c2951')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22528728-331b-48e8-a329-ab898d2c2951 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22528728-331b-48e8-a329-ab898d2c2951');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    file_name  person_id\n",
              "0  000001.jpg       2880\n",
              "1  000002.jpg       2937\n",
              "2  000003.jpg       8692\n",
              "3  000004.jpg       5805\n",
              "4  000005.jpg       9295"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure files are in order of file_name so indexing and label order is correct. Should be True.\n",
        "df.equals(df.sort_values(by='file_name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYLlr3UKR2c1",
        "outputId": "2178f5a3-389b-4d64-b562-cfe832ab9c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels of Images in One Shot Train Folder\n",
        "labels = df['person_id'].values.tolist()\n",
        "labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASV-UzpvR4me",
        "outputId": "bb99fb13-1d42-43a8-ed74-6a4ee3ea9010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2880, 2937, 8692, 5805, 9295]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(img_file_names)\n",
        "print(f'Number of Images in Dataset: {dataset_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWKnzmoo5k0b",
        "outputId": "b99d8d0a-5126-4607-b8f3-1c4c7e250a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images in Dataset: 10177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Transforms for Images"
      ],
      "metadata": {
        "id": "Duz9mLqq40_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation of Images in CelebA\n",
        "std_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "resize_dims = (256, 256) # GAN output dimensions can always be changed in transforms for our facenet model"
      ],
      "metadata": {
        "id": "CRYIPYn0bglE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5029f1xILCx",
        "outputId": "c1cd7f9c-1ed6-430f-f8dd-c34b0b894d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Cloning of HFGI Github Repo"
      ],
      "metadata": {
        "id": "Fjlz8HxkXONq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'HFGI'"
      ],
      "metadata": {
        "id": "O57_Q6avmJOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Tengfei-Wang/HFGI.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "metadata": {
        "id": "qFjMjp6tXPke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(f'./{CODE_DIR}')\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "1EUtaDTgXSav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etDz82xkTJz"
      },
      "source": [
        "## Download & Load Pretrained Models \n",
        "We provide pretrained models for face editing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSnjlBZOkTJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9686190d-80df-490d-fc25-9b7137a78698"
      },
      "source": [
        "#@title Download\n",
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory pretrained_models. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"checkpoint\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url    \n",
        "\n",
        "path = {\"id\": \"19y6pxOiJWB0NoG3fAZO9Eab66zkN9XIL\", \"name\": \"ckpt.pt\"}\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"]) \n",
        "\n",
        "!wget {download_command}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-21 23:29:50--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2022-11-21 23:29:50--  https://docs.google.com/uc?export=download&confirm=t&id=19y6pxOiJWB0NoG3fAZO9Eab66zkN9XIL\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.148.100, 142.250.148.138, 142.250.148.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.148.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-2k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9apln8s4lgkav8f9v8a0ej7p9k23unbl/1669073325000/17817459031648051118/*/19y6pxOiJWB0NoG3fAZO9Eab66zkN9XIL?e=download&uuid=112758c2-642b-4ab3-ba31-29c82e963219 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-21 23:29:50--  https://doc-0c-2k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9apln8s4lgkav8f9v8a0ej7p9k23unbl/1669073325000/17817459031648051118/*/19y6pxOiJWB0NoG3fAZO9Eab66zkN9XIL?e=download&uuid=112758c2-642b-4ab3-ba31-29c82e963219\n",
            "Resolving doc-0c-2k-docs.googleusercontent.com (doc-0c-2k-docs.googleusercontent.com)... 173.194.194.132, 2607:f8b0:4001:c10::84\n",
            "Connecting to doc-0c-2k-docs.googleusercontent.com (doc-0c-2k-docs.googleusercontent.com)|173.194.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1342891936 (1.2G) [application/x-zip]\n",
            "Saving to: ‘/HFGI/checkpoint/ckpt.pt’\n",
            "\n",
            "/HFGI/checkpoint/ck 100%[===================>]   1.25G   223MB/s    in 6.0s    \n",
            "\n",
            "2022-11-21 23:29:56 (212 MB/s) - ‘/HFGI/checkpoint/ckpt.pt’ saved [1342891936/1342891936]\n",
            "\n",
            "FINISHED --2022-11-21 23:29:56--\n",
            "Total wall clock time: 6.4s\n",
            "Downloaded: 1 files, 1.2G in 6.0s (212 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7osUvUYnaJht",
        "outputId": "df94534a-7e49-4f4b-915d-6cb3beb59e37"
      },
      "source": [
        "model_path = \"checkpoint/ckpt.pt\"\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['is_train'] = False\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading basic encoder from checkpoint: checkpoint/ckpt.pt\n",
            "Model successfully loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6oqf8JwzK0K"
      },
      "source": [
        "## Image Alignment using Dlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLDG7hJoOSqP"
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import scipy\n",
        "import scipy.ndimage\n",
        "import dlib\n",
        "\n",
        "\n",
        "def get_landmark(filepath, predictor):\n",
        "    \"\"\"get landmark with dlib\n",
        "    :return: np.array shape=(68, 2)\n",
        "    \"\"\"\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    img = dlib.load_rgb_image(filepath)\n",
        "    dets = detector(img, 1)\n",
        "\n",
        "    # dets is empty when dlib cannot detect a frontal face. Side profiles, etc\n",
        "    if not dets:\n",
        "      return None\n",
        "\n",
        "    for k, d in enumerate(dets):\n",
        "        shape = predictor(img, d)\n",
        "\n",
        "    t = list(shape.parts())\n",
        "    a = []\n",
        "    for tt in t:\n",
        "        a.append([tt.x, tt.y])\n",
        "    lm = np.array(a)\n",
        "    return lm\n",
        "\n",
        "\n",
        "def align_face(filepath, predictor):\n",
        "    \"\"\"\n",
        "    :param filepath: str\n",
        "    :return: PIL Image\n",
        "    \"\"\"\n",
        "\n",
        "    lm = get_landmark(filepath, predictor)\n",
        "\n",
        "    # when dlib cannot detect frontal face, return None\n",
        "    if lm is None:\n",
        "      return None\n",
        "\n",
        "    lm_chin = lm[0: 17]  # left-right\n",
        "    lm_eyebrow_left = lm[17: 22]  # left-right\n",
        "    lm_eyebrow_right = lm[22: 27]  # left-right\n",
        "    lm_nose = lm[27: 31]  # top-down\n",
        "    lm_nostrils = lm[31: 36]  # top-down\n",
        "    lm_eye_left = lm[36: 42]  # left-clockwise\n",
        "    lm_eye_right = lm[42: 48]  # left-clockwise\n",
        "    lm_mouth_outer = lm[48: 60]  # left-clockwise\n",
        "    lm_mouth_inner = lm[60: 68]  # left-clockwise\n",
        "\n",
        "    # Calculate auxiliary vectors.\n",
        "    eye_left = np.mean(lm_eye_left, axis=0)\n",
        "    eye_right = np.mean(lm_eye_right, axis=0)\n",
        "    eye_avg = (eye_left + eye_right) * 0.5\n",
        "    eye_to_eye = eye_right - eye_left\n",
        "    mouth_left = lm_mouth_outer[0]\n",
        "    mouth_right = lm_mouth_outer[6]\n",
        "    mouth_avg = (mouth_left + mouth_right) * 0.5\n",
        "    eye_to_mouth = mouth_avg - eye_avg\n",
        "\n",
        "    # Choose oriented crop rectangle.\n",
        "    x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
        "    x /= np.hypot(*x)\n",
        "    x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
        "    y = np.flipud(x) * [-1, 1]\n",
        "    c = eye_avg + eye_to_mouth * 0.1\n",
        "    quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
        "    qsize = np.hypot(*x) * 2\n",
        "\n",
        "    # read image\n",
        "    img = PIL.Image.open(filepath)\n",
        "\n",
        "    output_size = 256\n",
        "    transform_size = 256\n",
        "    enable_padding = True\n",
        "\n",
        "    # Shrink.\n",
        "    shrink = int(np.floor(qsize / output_size * 0.5))\n",
        "    if shrink > 1:\n",
        "        rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n",
        "        img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
        "        quad /= shrink\n",
        "        qsize /= shrink\n",
        "\n",
        "    # Crop.\n",
        "    border = max(int(np.rint(qsize * 0.1)), 3)\n",
        "    crop = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))), int(np.ceil(max(quad[:, 0]))),\n",
        "            int(np.ceil(max(quad[:, 1]))))\n",
        "    crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]),\n",
        "            min(crop[3] + border, img.size[1]))\n",
        "    if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
        "        img = img.crop(crop)\n",
        "        quad -= crop[0:2]\n",
        "\n",
        "    # Pad.\n",
        "    pad = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))), int(np.ceil(max(quad[:, 0]))),\n",
        "           int(np.ceil(max(quad[:, 1]))))\n",
        "    pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0),\n",
        "           max(pad[3] - img.size[1] + border, 0))\n",
        "    if enable_padding and max(pad) > border - 4:\n",
        "        pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
        "        img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
        "        h, w, _ = img.shape\n",
        "        y, x, _ = np.ogrid[:h, :w, :1]\n",
        "        mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w - 1 - x) / pad[2]),\n",
        "                          1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h - 1 - y) / pad[3]))\n",
        "        blur = qsize * 0.02\n",
        "        img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
        "        img += (np.median(img, axis=(0, 1)) - img) * np.clip(mask, 0.0, 1.0)\n",
        "        img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n",
        "        quad += pad[:2]\n",
        "\n",
        "    # Transform.\n",
        "    img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
        "    if output_size < transform_size:\n",
        "        img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
        "\n",
        "    # Return aligned image.\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if  'shape_predictor_68_face_landmarks.dat' not in os.listdir():\n",
        "    !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "    !bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "id": "QjSQECu23Rw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca915d4e-5a40-4436-858b-932840ab897e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-21 23:30:33--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  34.4MB/s    in 1.8s    \n",
            "\n",
            "2022-11-21 23:30:35 (34.4 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory\n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "R5hXx_-uiBkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = dlib.shape_predictor(\"HFGI/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
        "  if aligned_image is None: # dlib unable to detect frontal face\n",
        "    return None\n",
        "  return aligned_image"
      ],
      "metadata": {
        "id": "RDS_DeCMg3lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Code Functions for Inversions"
      ],
      "metadata": {
        "id": "cv6mrM8R9CQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_alongside_source_image(result_image, source_image):\n",
        "    res = np.concatenate([np.array(source_image.resize(resize_dims)),\n",
        "                          np.array(result_image.resize(resize_dims))], axis=1)\n",
        "    return Image.fromarray(res)\n",
        "\n",
        "def get_latents(net, x, is_cars=False):\n",
        "    codes = net.encoder(x)\n",
        "    if net.opts.start_from_latent_avg:\n",
        "        if codes.ndim == 2:\n",
        "            codes = codes + net.latent_avg.repeat(codes.shape[0], 1, 1)[:, 0, :]\n",
        "        else:\n",
        "            codes = codes + net.latent_avg.repeat(codes.shape[0], 1, 1)\n",
        "    if codes.shape[1] == 18 and is_cars:\n",
        "        codes = codes[:, :16, :]\n",
        "    return codes"
      ],
      "metadata": {
        "id": "G-QPf5TA9BNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Alignment on Images in CelebA One Shot & Storing Latent Codes"
      ],
      "metadata": {
        "id": "5lEWcvMnKrcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory for Latent Codes\n",
        "img_latent_codes_path = 'img_latent_codes'\n",
        "\n",
        "if not os.path.exists(img_latent_codes_path):\n",
        "  os.makedirs(img_latent_codes_path)"
      ],
      "metadata": {
        "id": "IowEznEyyYjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory for Distortion Maps \n",
        "img_distortions_path = 'img_distortion_maps'\n",
        "\n",
        "if not os.path.exists(img_distortions_path):\n",
        "  os.makedirs(img_distortions_path)"
      ],
      "metadata": {
        "id": "glXi7rkKygyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create file paths to store latent codes and distortion maps\n",
        "l_paths = [os.path.join(img_latent_codes_path, name + '.pt') for name in f_num]\n",
        "d_paths = [os.path.join(img_distortions_path, name +'.pt') for name in f_num]"
      ],
      "metadata": {
        "id": "oLau04dt2uzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_face = []\n",
        "inference_times = [] # Store Inference Times Just to Understand Computation Time\n",
        "\n",
        "for i, path in tqdm(enumerate(img_file_paths), total=len(img_file_paths)):  \n",
        "  input_image = run_alignment(path) # should return a (256, 256) PIL Image\n",
        "\n",
        "  if input_image is None: # dlib unable to detect frontal face\n",
        "    no_face.append((img_file_names[i], i))\n",
        "    input_image = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "  img = std_transform(input_image) # perform transformation on image\n",
        "\n",
        "  # Inversion Code of Images in Dataset\n",
        "  with torch.no_grad():\n",
        "    x = img.unsqueeze(0).cuda()\n",
        "\n",
        "    # get latent codes\n",
        "    tic = time.time()\n",
        "    latent_codes = get_latents(net, x)\n",
        "    torch.save(latent_codes[0], l_paths[i]) # (18, 512)\n",
        "    \n",
        "    # calculate the distortion map\n",
        "    imgs, _ = net.decoder([latent_codes[0].unsqueeze(0).cuda()],None, input_is_latent=True, randomize_noise=False, return_latents=True)\n",
        "    res = x -  torch.nn.functional.interpolate(torch.clamp(imgs, -1., 1.), size=(256,256) , mode='bilinear') # (1, 3, 256, 256)\n",
        "    torch.save(res, d_paths[i]) # (1, 3, 256, 256)\n",
        "      \n",
        "    toc = time.time()\n",
        "    inference_times.append(round(toc-tic, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pacp4ziy8ncZ",
        "outputId": "2d4bb8a9-b6ec-4ed6-8455-a2d0eef37fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10177 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10177/10177 [1:18:08<00:00,  2.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total Number of Images: {len(l_paths)}')\n",
        "print(f'Number of Images Undetected by Dlib: {len(no_face)}')\n",
        "print(f'Max Inference Time was : {max(inference_times)} seconds')\n",
        "print(f'Median Inference Time was: {np.median(inference_times)} seconds')\n",
        "print(f'Total Inference Time was: {sum(inference_times):4f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "httPv3On-Aea",
        "outputId": "888827b0-adce-4802-984f-4d2d7533542d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Images: 10177\n",
            "Number of Images Undetected by Dlib: 343\n",
            "Max Inference Time was : 0.4868 seconds\n",
            "Median Inference Time was: 0.1186 seconds\n",
            "Total Inference Time was: 1206.743600 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load GAN Editings for Semantic Image Augmentation"
      ],
      "metadata": {
        "id": "79f-UzGmY4i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory to access editings\n",
        "os.chdir('HFGI')\n",
        "\n",
        "from editings import latent_editor\n",
        "editor = latent_editor.LatentEditor(net.decoder)\n",
        "\n",
        "# change directory back to content to save files \n",
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "9iX2UkpZZBcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvSrYb-BLWjM"
      },
      "source": [
        "# interface-GAN\n",
        "interfacegan_directions = {\n",
        "        'age': 'HFGI/editings/interfacegan_directions/age.pt',\n",
        "        'smile': 'HFGI/editings/interfacegan_directions/smile.pt',\n",
        "        'pose': 'HFGI/editings/interfacegan_directions/pose.pt' }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebHxnm98LWjN"
      },
      "source": [
        "# GANSpace\n",
        "ganspace_pca = torch.load('HFGI/editings/ganspace_pca/ffhq_pca.pt') \n",
        "ganspace_directions = {\n",
        "    'eyes':            (54,  7,  8,  20),\n",
        "    'beard':           (58,  7,  9,  -20),\n",
        "    'lip':             (34, 10, 11,  20) }            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtdO1cFOLWjM"
      },
      "source": [
        "## High-Fidelity Editing - Pose (INTERFACE GAN)\n",
        "**(AUGMENTATION #1)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edit_direction = torch.load(interfacegan_directions['pose']).cuda()\n",
        "edit_degree = 2"
      ],
      "metadata": {
        "id": "qf_AKcBYEGKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to Save HGFI Pose Augmented Images\n",
        "if not os.path.exists('celeba_train_hfgi_pose'):\n",
        "  os.mkdir('celeba_train_hfgi_pose')"
      ],
      "metadata": {
        "id": "jm69guYjGC8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pose_folder = 'celeba_train_hfgi_pose'"
      ],
      "metadata": {
        "id": "kuqNxmnqY1D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hfgi pose augmentation\n",
        "pose_aug_fnames = []\n",
        "\n",
        "for i in tqdm(range(dataset_size)):\n",
        "  img_latent_code = torch.load(l_paths[i]) # tensor (18,512)\n",
        "  img_edit, edit_latents = editor.apply_interfacegan(img_latent_code.unsqueeze(0).cuda(), edit_direction, factor=edit_degree)\n",
        "\n",
        "  # align the distortion map\n",
        "  img_edit = torch.nn.functional.interpolate(torch.clamp(img_edit, -1., 1.), size=(256,256) , mode='bilinear')\n",
        "  img_distortion_map = torch.load(d_paths[i]) # tensor (1, 3, 256, 256)\n",
        "  res_align  = net.grid_align(torch.cat((img_distortion_map, img_edit  ), 1))\n",
        "\n",
        "  # fusion\n",
        "  conditions = net.residue(res_align)\n",
        "  result, _ = net.decoder([edit_latents],conditions, input_is_latent=True, randomize_noise=False, return_latents=True)\n",
        "\n",
        "  result = torch.nn.functional.interpolate(result, size=(256,256) , mode='bilinear')\n",
        "\n",
        "  #saving augmented images as jpg\n",
        "  img_obj = tensor2im(result[0]) # (256, 256) Convert tensor (3, 256, 256) to Image (256, 256)\n",
        "  aug_name = f_num[i] + '_' + 'pose' + '.jpg'\n",
        "  pose_aug_fnames.append(aug_name)\n",
        "  img_path = os.path.join(pose_folder, aug_name)\n",
        "  img_obj.save(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvHubbFRXsYZ",
        "outputId": "df3bfebf-0480-40f8-bfd6-27ddf429a713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10177 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10177/10177 [25:17<00:00,  6.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create zip file to download augmented images\n",
        "back_up(pose_folder)"
      ],
      "metadata": {
        "id": "Fk5W0zi-jr5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6b14fbb-b44d-4e42-e98c-ed28777ceee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1e7903d6-99cc-4e90-b4ea-544e2d01c2dc\", \"celeba_train_hfgi_pose.zip\", 85800742)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip file created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create labels mapping file for data augmented images\n",
        "zip_pose = list(zip(pose_aug_fnames, labels))\n",
        "df_pose = pd.DataFrame(zip_pose, columns=[\"file_name\", \"person_id\"])\n",
        "df_pose.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D4BF9E66dPwi",
        "outputId": "57369649-1e28-4184-820b-83aff01b5de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d0a0d0ba-68dd-47e6-bb32-c1ec8a913d47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001_pose.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002_pose.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003_pose.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004_pose.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005_pose.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0a0d0ba-68dd-47e6-bb32-c1ec8a913d47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0a0d0ba-68dd-47e6-bb32-c1ec8a913d47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0a0d0ba-68dd-47e6-bb32-c1ec8a913d47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         file_name  person_id\n",
              "0  000001_pose.jpg       2880\n",
              "1  000002_pose.jpg       2937\n",
              "2  000003_pose.jpg       8692\n",
              "3  000004_pose.jpg       5805\n",
              "4  000005_pose.jpg       9295"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save mapping file\n",
        "np.savetxt('labels_hfgi_pose_celeba.txt', df_pose, fmt = \"%s\")"
      ],
      "metadata": {
        "id": "lS0tWHYnfQM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-Fidelity Editing - Smile (INTERFACE GAN)\n",
        "**(AUGMENTATION #2)**"
      ],
      "metadata": {
        "id": "-erPWTgyhZxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit_direction = torch.load(interfacegan_directions['smile']).cuda()\n",
        "edit_degree = 1.5"
      ],
      "metadata": {
        "id": "0KBR4-w9w17z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to Save HGFI Smile Augmented Images\n",
        "if not os.path.exists('celeba_train_hfgi_smile'):\n",
        "  os.mkdir('celeba_train_hfgi_smile')"
      ],
      "metadata": {
        "id": "s-CvIsTVw19o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smile_folder = 'celeba_train_hfgi_smile'"
      ],
      "metadata": {
        "id": "OOnDCIhBY332"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hfgi smile augmentation\n",
        "smile_aug_fnames = []\n",
        "\n",
        "for i in tqdm(range(dataset_size)):\n",
        "  img_latent_code = torch.load(l_paths[i]) # tensor (18,512)\n",
        "  img_edit, edit_latents = editor.apply_interfacegan(img_latent_code.unsqueeze(0).cuda(), edit_direction, factor=edit_degree)\n",
        "\n",
        "  # align the distortion map\n",
        "  img_edit = torch.nn.functional.interpolate(torch.clamp(img_edit, -1., 1.), size=(256,256) , mode='bilinear')\n",
        "  img_distortion_map = torch.load(d_paths[i]) # tensor (1, 3, 256, 256)\n",
        "  res_align  = net.grid_align(torch.cat((img_distortion_map, img_edit  ), 1))\n",
        "\n",
        "  # fusion\n",
        "  conditions = net.residue(res_align)\n",
        "  result, _ = net.decoder([edit_latents],conditions, input_is_latent=True, randomize_noise=False, return_latents=True)\n",
        "\n",
        "  result = torch.nn.functional.interpolate(result, size=(256,256) , mode='bilinear')\n",
        "\n",
        "  #saving augmented images as jpg\n",
        "  img_obj = tensor2im(result[0]) # (256, 256) Convert tensor (3, 256, 256) to Image (256, 256)\n",
        "  aug_name = f_num[i] + '_' + 'smile' + '.jpg'\n",
        "  smile_aug_fnames.append(aug_name)\n",
        "  img_path = os.path.join(smile_folder, aug_name)\n",
        "  img_obj.save(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3215dabd-3fa6-438f-e74f-969c667fe016",
        "id": "1qLm7uRvj6jz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10177 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10177/10177 [25:31<00:00,  6.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create zip file to download augmented images\n",
        "back_up(smile_folder)"
      ],
      "metadata": {
        "id": "OIor_lt4j6j0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ce67147-ec50-4d5d-d031-3e3220c190ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4e7e2912-8be2-4689-bc42-9850a42e3a85\", \"celeba_train_hfgi_smile.zip\", 84633904)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip file created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create labels mapping file for data augmented images\n",
        "zip_smile = list(zip(smile_aug_fnames, labels))\n",
        "df_smile = pd.DataFrame(zip_smile, columns=[\"file_name\", \"person_id\"])\n",
        "df_smile.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6333583f-63be-44be-ae45-28c833bac14e",
        "id": "9B0uTVaTj6j0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d0be0fea-3623-4bd7-a755-b39c907686ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001_smile.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002_smile.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003_smile.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004_smile.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005_smile.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0be0fea-3623-4bd7-a755-b39c907686ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0be0fea-3623-4bd7-a755-b39c907686ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0be0fea-3623-4bd7-a755-b39c907686ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          file_name  person_id\n",
              "0  000001_smile.jpg       2880\n",
              "1  000002_smile.jpg       2937\n",
              "2  000003_smile.jpg       8692\n",
              "3  000004_smile.jpg       5805\n",
              "4  000005_smile.jpg       9295"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save mapping file\n",
        "np.savetxt('labels_hfgi_smile_celeba.txt', df_smile, fmt = \"%s\")"
      ],
      "metadata": {
        "id": "31SSfNWaj6j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-Fidelity Editing - Age (INTERFACE GAN)\n",
        "**(AUGMENTATION #3)**"
      ],
      "metadata": {
        "id": "FQ5qrdTRB1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit_direction = torch.load(interfacegan_directions['age']).cuda()\n",
        "edit_degree = 2.5"
      ],
      "metadata": {
        "id": "pVtu7tzGB1Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to Save HGFI Age Augmented Images\n",
        "if not os.path.exists('celeba_train_hfgi_age'):\n",
        "  os.mkdir('celeba_train_hfgi_age')"
      ],
      "metadata": {
        "id": "UoBneh5CB1Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_folder = 'celeba_train_hfgi_age'"
      ],
      "metadata": {
        "id": "oeG8ylfqB1Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hfgi age augmentation\n",
        "age_aug_fnames = []\n",
        "\n",
        "for i in tqdm(range(dataset_size)):\n",
        "  img_latent_code = torch.load(l_paths[i]) # tensor (18,512)\n",
        "  img_edit, edit_latents = editor.apply_interfacegan(img_latent_code.unsqueeze(0).cuda(), edit_direction, factor=edit_degree)\n",
        "\n",
        "  # align the distortion map\n",
        "  img_edit = torch.nn.functional.interpolate(torch.clamp(img_edit, -1., 1.), size=(256,256) , mode='bilinear')\n",
        "  img_distortion_map = torch.load(d_paths[i]) # tensor (1, 3, 256, 256)\n",
        "  res_align  = net.grid_align(torch.cat((img_distortion_map, img_edit  ), 1))\n",
        "\n",
        "  # fusion\n",
        "  conditions = net.residue(res_align)\n",
        "  result, _ = net.decoder([edit_latents],conditions, input_is_latent=True, randomize_noise=False, return_latents=True)\n",
        "\n",
        "  result = torch.nn.functional.interpolate(result, size=(256,256) , mode='bilinear')\n",
        "\n",
        "  #saving augmented images as jpg\n",
        "  img_obj = tensor2im(result[0]) # (256, 256) Convert tensor (3, 256, 256) to Image (256, 256)\n",
        "  aug_name = f_num[i] + '_' + 'age' + '.jpg'\n",
        "  age_aug_fnames.append(aug_name)\n",
        "  img_path = os.path.join(age_folder, aug_name)\n",
        "  img_obj.save(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d5dea8-62b8-4704-ebb1-5a3536aef6c9",
        "id": "3A1gLiAbB1Gs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10177 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10177/10177 [27:35<00:00,  6.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create zip file to download augmented images\n",
        "back_up(age_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17d1b79e-9315-4178-f3cb-f4096418d889",
        "id": "f00ZIj6SB1Gt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7243c9e0-9bef-4077-ab10-363e672ad968\", \"celeba_train_hfgi_age.zip\", 87997898)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip file created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create labels mapping file for data augmented images\n",
        "zip_age = list(zip(age_aug_fnames, labels))\n",
        "df_age = pd.DataFrame(zip_age, columns=[\"file_name\", \"person_id\"])\n",
        "df_age.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "efd2b7ac-bf89-4bef-840c-603f0a28aa5a",
        "id": "C1XSe_5EB1Gt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d98d4d2b-fdaa-4138-9e02-ec922672f93b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001_age.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002_age.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003_age.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004_age.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005_age.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d98d4d2b-fdaa-4138-9e02-ec922672f93b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d98d4d2b-fdaa-4138-9e02-ec922672f93b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d98d4d2b-fdaa-4138-9e02-ec922672f93b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        file_name  person_id\n",
              "0  000001_age.jpg       2880\n",
              "1  000002_age.jpg       2937\n",
              "2  000003_age.jpg       8692\n",
              "3  000004_age.jpg       5805\n",
              "4  000005_age.jpg       9295"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save mapping file\n",
        "np.savetxt('labels_hfgi_age_celeba.txt', df_age, fmt = \"%s\")"
      ],
      "metadata": {
        "id": "Ue_4DuMbB1Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-Fidelity Editing - Eyes (GANSPACE)\n",
        "**(AUGMENTATION #4)**"
      ],
      "metadata": {
        "id": "6Cc1arBgoMXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit_direction = ganspace_directions['eyes']"
      ],
      "metadata": {
        "id": "W_Un0yd5mnXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to Save HGFI Eyes Augmented Images\n",
        "if not os.path.exists('celeba_train_hfgi_eyes'):\n",
        "  os.mkdir('celeba_train_hfgi_eyes')"
      ],
      "metadata": {
        "id": "x-yItJOjoRzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eyes_folder = 'celeba_train_hfgi_eyes'"
      ],
      "metadata": {
        "id": "MwTIGliaY5zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hfgi eyes augmentation\n",
        "eyes_aug_fnames = []\n",
        "\n",
        "for i in tqdm(range(dataset_size)):\n",
        "  img_latent_code = torch.load(l_paths[i]) # tensor (18,512)\n",
        "  img_edit, edit_latents = editor.apply_ganspace(img_latent_code.unsqueeze(0).cuda(), ganspace_pca, [edit_direction])\n",
        "\n",
        "  # align the distortion map\n",
        "  img_edit = torch.nn.functional.interpolate(torch.clamp(img_edit, -1., 1.), size=(256,256) , mode='bilinear')\n",
        "  img_distortion_map = torch.load(d_paths[i]) # tensor (1, 3, 256, 256)\n",
        "  res_align  = net.grid_align(torch.cat((img_distortion_map, img_edit  ), 1))\n",
        "\n",
        "  # fusion\n",
        "  conditions = net.residue(res_align)\n",
        "  result, _ = net.decoder([edit_latents],conditions, input_is_latent=True, randomize_noise=False, return_latents=True)\n",
        "\n",
        "  result = torch.nn.functional.interpolate(result, size=(256,256) , mode='bilinear')\n",
        "\n",
        "  #saving augmented images as jpg\n",
        "  img_obj = tensor2im(result[0]) # (256, 256) Convert tensor (3, 256, 256) to Image (256, 256)\n",
        "  aug_name = f_num[i] + '_' + 'eyes' + '.jpg'\n",
        "  eyes_aug_fnames.append(aug_name)\n",
        "  img_path = os.path.join(eyes_folder, aug_name)\n",
        "  img_obj.save(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-keDlSuvoeOl",
        "outputId": "f2d2e5c2-d43a-44a0-852a-c1646a647d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10177 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10177/10177 [25:33<00:00,  6.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create zip file to download augmented images\n",
        "back_up(eyes_folder)"
      ],
      "metadata": {
        "id": "ZGcelcx6pMHt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d910986a-1c13-467e-b307-876378a17955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f28a2a88-e438-469f-bfa5-c68313c1a281\", \"celeba_train_hfgi_eyes.zip\", 82012612)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip file created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create labels mapping file for data augmented images\n",
        "zip_eyes = list(zip(eyes_aug_fnames, labels))\n",
        "df_eyes = pd.DataFrame(zip_eyes, columns=[\"file_name\", \"person_id\"])\n",
        "df_eyes.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "70095114-19b5-490c-bf54-a451e577210f",
        "id": "FJz1uPo0pMHt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-413ff9ad-359d-4769-93c9-2e0c7a7ab48a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001_eyes.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002_eyes.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003_eyes.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004_eyes.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005_eyes.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-413ff9ad-359d-4769-93c9-2e0c7a7ab48a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-413ff9ad-359d-4769-93c9-2e0c7a7ab48a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-413ff9ad-359d-4769-93c9-2e0c7a7ab48a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         file_name  person_id\n",
              "0  000001_eyes.jpg       2880\n",
              "1  000002_eyes.jpg       2937\n",
              "2  000003_eyes.jpg       8692\n",
              "3  000004_eyes.jpg       5805\n",
              "4  000005_eyes.jpg       9295"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save mapping file\n",
        "np.savetxt('labels_hfgi_eyes_celeba.txt', df_eyes, fmt = \"%s\")"
      ],
      "metadata": {
        "id": "9tId8aQ6pMHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-Fidelity Editing - Lip (GANSPACE)\n",
        "**(AUGMENTATION #5)**"
      ],
      "metadata": {
        "id": "iuAHvlxqqjV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit_direction = ganspace_directions['lip']"
      ],
      "metadata": {
        "id": "XNMbkrOHqp5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Directory to Save HGFI Lip Augmented Images\n",
        "if not os.path.exists('celeba_train_hfgi_lip'):\n",
        "  os.mkdir('celeba_train_hfgi_lip')"
      ],
      "metadata": {
        "id": "xwgBk7HCqp5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lip_folder = 'celeba_train_hfgi_lip'"
      ],
      "metadata": {
        "id": "05ZFKzQzY8DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hfgi lip augmentation\n",
        "lip_aug_fnames = []\n",
        "\n",
        "for i in tqdm(range(dataset_size)):\n",
        "  img_latent_code = torch.load(l_paths[i]) # tensor (18,512)\n",
        "  img_edit, edit_latents = editor.apply_ganspace(img_latent_code.unsqueeze(0).cuda(), ganspace_pca, [edit_direction])\n",
        "\n",
        "  # align the distortion map\n",
        "  img_edit = torch.nn.functional.interpolate(torch.clamp(img_edit, -1., 1.), size=(256,256) , mode='bilinear')\n",
        "  img_distortion_map = torch.load(d_paths[i]) # tensor (1, 3, 256, 256)\n",
        "  res_align  = net.grid_align(torch.cat((img_distortion_map, img_edit  ), 1))\n",
        "\n",
        "  # fusion\n",
        "  conditions = net.residue(res_align)\n",
        "  result, _ = net.decoder([edit_latents],conditions, input_is_latent=True, randomize_noise=False, return_latents=True)\n",
        "\n",
        "  result = torch.nn.functional.interpolate(result, size=(256,256) , mode='bilinear')\n",
        "\n",
        "  #saving augmented images as jpg\n",
        "  img_obj = tensor2im(result[0]) # (256, 256) Convert tensor (3, 256, 256) to Image (256, 256)\n",
        "  aug_name = f_num[i] + '_' + 'lip' + '.jpg'\n",
        "  lip_aug_fnames.append(aug_name)\n",
        "  img_path = os.path.join(lip_folder, aug_name)\n",
        "  img_obj.save(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv-zFzR9qp5N",
        "outputId": "137abad2-1bd0-42c2-a4f8-b99faf3f9cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10177 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10177/10177 [25:33<00:00,  6.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create zip file to download augmented images\n",
        "back_up(lip_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fbZe3qPyq7re",
        "outputId": "6295f17d-ef17-4163-cd0c-e57f7080afe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a0377956-6046-4281-a04c-ded39b6c3b1b\", \"celeba_train_hfgi_lip.zip\", 83843239)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip file created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create labels mapping file for data augmented images\n",
        "zip_lip = list(zip(lip_aug_fnames, labels))\n",
        "df_lip = pd.DataFrame(zip_lip, columns=[\"file_name\", \"person_id\"])\n",
        "df_lip.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e83b56ea-dd81-4da1-8729-68a6a428696d",
        "id": "-Z5KfDhaq7rf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0fc54fea-d1fb-46f1-9320-d59a4f217cb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001_lip.jpg</td>\n",
              "      <td>2880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002_lip.jpg</td>\n",
              "      <td>2937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003_lip.jpg</td>\n",
              "      <td>8692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004_lip.jpg</td>\n",
              "      <td>5805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005_lip.jpg</td>\n",
              "      <td>9295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc54fea-d1fb-46f1-9320-d59a4f217cb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fc54fea-d1fb-46f1-9320-d59a4f217cb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fc54fea-d1fb-46f1-9320-d59a4f217cb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        file_name  person_id\n",
              "0  000001_lip.jpg       2880\n",
              "1  000002_lip.jpg       2937\n",
              "2  000003_lip.jpg       8692\n",
              "3  000004_lip.jpg       5805\n",
              "4  000005_lip.jpg       9295"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save mapping file\n",
        "np.savetxt('labels_hfgi_lip_celeba.txt', df_lip, fmt = \"%s\")"
      ],
      "metadata": {
        "id": "1qHPCN6Yq7rf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}